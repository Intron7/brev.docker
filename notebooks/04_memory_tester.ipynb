{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "606d38d2",
   "metadata": {},
   "source": [
    "# Testing Memory Management with RAPIDS\n",
    "\n",
    "This notebook demonstrates the impact of RAPIDS Memory Manager (RMM) configuration on GPU-accelerated single-cell analysis, specifically focusing on Harmony batch correction.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Harmony batch correction performs frequent allocation and deallocation of GPU arrays during its iterative optimization process. This makes it particularly sensitive to memory management overhead and bandwidth constraints. RMM configuration can significantly impact Harmony's performance by:\n",
    "\n",
    "- **Reducing allocation overhead**: Memory pooling eliminates the cost of repeated malloc/free operations\n",
    "- **Improving bandwidth utilization**: Efficient memory reuse reduces memory bandwidth bottlenecks\n",
    "- **Faster execution**: Minimizing allocation/deallocation cycles speeds up the overall workflow\n",
    "\n",
    "## What is RMM?\n",
    "\n",
    "The RAPIDS Memory Manager (RMM) provides efficient GPU memory allocation and pooling strategies that can significantly improve performance by:\n",
    "- Reducing allocation overhead through memory pooling\n",
    "- Supporting memory oversubscription with managed memory\n",
    "- Providing fine-grained control over GPU memory usage\n",
    "\n",
    "This notebook will compare different RMM configurations and their effects on Harmony batch correction workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cea3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rapids_singlecell as rsc\n",
    "import scanpy as sc\n",
    "import rmm\n",
    "import cupy as cp\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import decoupler as dc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4128bac4",
   "metadata": {},
   "source": [
    "ℹ️ Note: The dataset used in this notebook is generated in `01_demo_gpu.ipynb`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4007bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(\"h5/dli_decoupler.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aae05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rmm.allocators.cupy import rmm_cupy_allocator\n",
    "rmm.reinitialize(\n",
    "    managed_memory=False, # Allows oversubscription\n",
    "    pool_allocator=True, # default is False\n",
    ")\n",
    "cp.cuda.set_allocator(rmm_cupy_allocator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d06726",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rsc.pp.harmony_integrate(adata, key=\"assay\", dtype=cp.float32)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
